{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 2: \n",
    "\n",
    "Same as above, but this time you export the result to a CSV, then you take the CSV and upload it to the database again \n",
    "\n",
    "Steps: \n",
    "Get the data from the database and export it to a CSV. There are multiple ways on how to do this: \n",
    "* run a Postgres query with the PostgresOperator that exports a CSV on your system (easy) The command you are looking for is COPY \n",
    "* use the PythonOperator to get the data from the database and stores it as a CSV (medium) - You might want to use the python library psycopg2 and pandas for this\n",
    "* use the Airflow Hooks to build your own Operator (hard) -> this is the preferred method. Check the airflow documentation for Operators to see how this is build (this is an overkill for the task, but worthwhile checking it)\n",
    "\n",
    "Read the CSV file and store it in the database again, also multiple ways possible\n",
    "* run a query with the PostgresOperator that imports the CSV into a table (easy)\n",
    "* use the PythonOperator to save the data into the database (medium)\n",
    "* use Python in conjunction with the airflow PostgresHook to build your own Operator (hard) \n",
    "\n",
    "This task is heavily emphasized on getting your hands dirty with airflow and python :-)\n",
    "\n",
    "\n",
    "Here are some resources, that is very helpful: \n",
    "airflow documentation: https://airflow.apache.org/ -> There is a tutorial, you should definitely do first\n",
    "airflow GitHub repository: https://github.com/apache/incubator-airflow (good to understand the Hooks and Operators in a very granular Detail) \n",
    "airflow ETL principles https://gtoonstra.github.io/etl-with-airflow/principles.html (very advanced, you do not have to read this, it is just as an additional resource here)\n",
    "\n",
    "psycopg2 documentation http://initd.org/psycopg/docs/ (to connect python with Postgres)\n",
    "pandas documentation https://pandas.pydata.org/pandas-docs/stable/ (for data manipulation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import airflow\n",
    "\n",
    "# The DAG object; we'll need this to instantiate a DAG\n",
    "from airflow import DAG\n",
    "\n",
    "# Operators; we need this to operate!\n",
    "from airflow.operators.bash_operator import BashOperator\n",
    "from airflow.operators.postgres_operator import PostgresOperator\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "\n",
    "from airflow.models import Variable\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': airflow.utils.dates.days_ago(1),\n",
    "    'email': ['tjdcevans@gmail.com'],\n",
    "    'email_on_failure': False,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "    # 'queue': 'bash_queue',\n",
    "    # 'pool': 'backfill',\n",
    "    # 'priority_weight': 10,\n",
    "    # 'end_date': datetime(2016, 1, 1),\n",
    "}\n",
    "\n",
    "connection_parameters = {\n",
    "    'host' : 'localhost',\n",
    "    'port' : '5432',\n",
    "    'dbname' : 'asana',\n",
    "    'user' : 'theoevans'\n",
    "}\n",
    "\n",
    "filepath = Variable.get('asana_data') + 'completed_tasks.csv'\n",
    "\n",
    "fetch_query = \"\"\"\n",
    "    SELECT u.name as name,\n",
    "        COUNT(*) as tasks,\n",
    "        COUNT(NULLIF(completed, 'False') ) as complete,\n",
    "        COUNT(NULLIF(completed, 'True') ) as incomplete\n",
    "    FROM tasks t\n",
    "    LEFT JOIN users u ON u.id = t.assignee_id\n",
    "    GROUP BY u.name;\"\"\"\n",
    "\n",
    "insert_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS completed_tasks\n",
    "    (\n",
    "        name varchar(255),\n",
    "        tasks bigint,\n",
    "        complete bigint,\n",
    "        incomplete bigint\n",
    "    );\n",
    "    \n",
    "    COPY completed_tasks\n",
    "    FROM '%s' DELIMITER ',' CSV HEADER;\n",
    "    \"\"\" % filepath\n",
    "\n",
    "dag = DAG('asana_postgres_v2', default_args=default_args, schedule_interval=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_query():\n",
    "    conn = psychopg2.connect(**connection_parameters)\n",
    "    with conn.cursor() as cursor: \n",
    "        cursor.execute(fetch_query)\n",
    "        fetch = cursor.fetchall()\n",
    "    conn.close()\n",
    "    df = pd.DataFrame(fetch)\n",
    "    df.to_csv(filepath)\n",
    "    \n",
    "def import_query():\n",
    "    conn = psychopg2.connect(**connection_parameters)\n",
    "    with conn.cursor() as cursor: \n",
    "        cursor.execute(insert_query)\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = PythonOperator(\n",
    "    task_id='query_db_and_export',\n",
    "    python_callable=export_query,\n",
    "    dag=dag)\n",
    "\n",
    "t2 = PythonOperator(\n",
    "    task_id='import_csv_to_db',\n",
    "    python_callable=import_query,\n",
    "    dag=dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.set_downstream(t1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
